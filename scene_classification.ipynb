{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "scene_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulgupta-G/SceneClassification/blob/master/scene_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lf_7805PvGgZ",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import os\n",
        "import PIL\n",
        "# from jupyterthemes import jtplot\n",
        "# jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False) \n",
        "# setting the style of the notebook to be monokai theme  \n",
        "# this line of code is important to ensure that we are able to see the x and y axes clearly\n",
        "# If you don't run this code line, you will notice that the xlabel and ylabel on any plot is black on black and it will be hard to see them. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npU3XDrb9rKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the number of images in training, validation and test dataset\n",
        "train = []\n",
        "test = []\n",
        "# os.listdir returns the list of files in the folder, in this case image class names\n",
        "for i in os.listdir('./file_path'):\n",
        "  train_class = os.listdir(os.path.join('seg_train', i))\n",
        "  train.extend(train_class)\n",
        "  test_class = os.listdir(os.path.join('seg_test', i))\n",
        "  test.extend(test_class)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8bw_N3GC2GPi",
        "colab": {}
      },
      "source": [
        "# Visualize the images in the dataset\n",
        "\n",
        "fig, axs = plt.subplots(6,5, figsize=(32,32))\n",
        "count = 0\n",
        "for i in os.listdir('./file_path'):\n",
        "  # get the list of images in the particular class\n",
        "  train_class = os.listdir(os.path.join('seg_train',i))\n",
        "  # plot 5 images per class\n",
        "\n",
        "fig.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BgmZEvwgIzqc",
        "colab": {}
      },
      "source": [
        "# check the number of images in each class in the training dataset\n",
        "\n",
        "No_images_per_class = []\n",
        "Class_name = []\n",
        "for i in os.listdir('./seg_train'):\n",
        "  train_class = os.listdir(os.path.join('seg_train', i))\n",
        "  No_images_per_class.append(len(train_class))\n",
        "  Class_name.append(i)\n",
        "  print('Number of images in {} = {} \\n'.format(i, len(train_class)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7phFxj7xuUP4",
        "colab": {}
      },
      "source": [
        "# create run-time augmentation on training and test dataset\n",
        "# For training datagenerator, we add normalization, shear angle, zooming range and horizontal flip\n",
        "\n",
        "\n",
        "# For test datagenerator, we only normalize the data.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0gD1o9WpyOwy",
        "colab": {}
      },
      "source": [
        "# Creating datagenerator for training, validation and test dataset.\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'seg_train',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset ='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        'seg_train',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset ='validation')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DuDXHzHwz3dR",
        "colab": {}
      },
      "source": [
        "def res_block(X, filter, stage):\n",
        "  \n",
        "  # Convolutional_block\n",
        "  X_copy = X\n",
        "\n",
        "  f1 , f2, f3 = filter\n",
        "    \n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = MaxPool2D((2,2))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
        "\n",
        "\n",
        "  # Short path\n",
        "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
        "  X_copy = MaxPool2D((2,2))(X_copy)\n",
        "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Identity Block 1\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Identity Block 2\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1HLFCO1H05C2",
        "colab": {}
      },
      "source": [
        "\n",
        "input_shape = (256,256,3)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Zero-padding\n",
        "X = ZeroPadding2D((3,3))(X_input)\n",
        "\n",
        "# 1 - stage\n",
        "X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
        "X = Activation('relu')(X)\n",
        "X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
        "\n",
        "# 2- stage\n",
        "X = res_block(X, filter= [64,64,256], stage= 2)\n",
        "\n",
        "# 3- stage\n",
        "X = res_block(X, filter= [128,128,512], stage= 3)\n",
        "\n",
        "# 4- stage\n",
        "X = res_block(X, filter= [256,256,1024], stage= 4)\n",
        "\n",
        "# 5- stage\n",
        "X = res_block(X, filter= [512,512,2048], stage= 5)\n",
        "\n",
        "# Average Pooling\n",
        "X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
        "\n",
        "# Final layer\n",
        "X = Flatten()(X)\n",
        "X = Dense(6, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "\n",
        "\n",
        "model = Model( inputs= X_input, outputs = X, name = 'Resnet18')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EN_NR37Z07Z-",
        "colab": {}
      },
      "source": [
        "# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "utpCBuch5K5j",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, steps_per_epoch= train_generator.n // 32, epochs = 1, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer , earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ox5UpdcIe1L",
        "colab": {}
      },
      "source": [
        "# Evaluate the performance of the model\n",
        "evaluate = model.evaluate_generator(test_generator, steps = test_generator.n // 32, verbose =1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GmXWmLQPOGCc",
        "colab": {}
      },
      "source": [
        "# assign label names to the corresponding indexes\n",
        "labels = {0: 'buildings', 1: 'forest', 2: 'glacier', 3:'mountain', 4: 'sea', 5:'street'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ja8K9HDUMvXN",
        "colab": {}
      },
      "source": [
        "# load images and their predictions \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "# import cv2\n",
        "\n",
        "prediction = []\n",
        "original = []\n",
        "image = []\n",
        "count = 0\n",
        "for i in os.listdir('./seg_test'):\n",
        "  for item in os.listdir(os.path.join('./seg_test', i)):\n",
        "    # code to open the image\n",
        "    img= PIL.Image.open(os.path.join('./seg_test', i, item))\n",
        "    # resizing the image to (256,256)\n",
        "    img = img.resize((256, 256))\n",
        "    # appending image to the image list\n",
        "    image.append(img)\n",
        "    # converting image to array\n",
        "    img = np.asarray(img, dtype = np.float32)\n",
        "    # normalizing the image\n",
        "    img = img / 255\n",
        "    # reshaping the image into a 4D array\n",
        "    img = img.reshape(-1, 256, 256, 3)\n",
        "    # making prediction of the model\n",
        "    predict = model.predict(img)\n",
        "    # getting the index corresponding to the highest value in the prediction\n",
        "    predict = np.argmax(predict)\n",
        "    # appending the predicted class to the list\n",
        "    prediction.append(labels[predict])\n",
        "    # appending original class to the list\n",
        "    original.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJF0bF1xSE10",
        "colab": {}
      },
      "source": [
        "# Get the test accuracy \n",
        "score = accuracy_score(original, prediction)\n",
        "print(\"Test Accuracy : {}\".format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uIi_GI-oSG1a",
        "colab": {}
      },
      "source": [
        "# visualize the results\n",
        "import random\n",
        "fig = plt.figure(figsize = (100,100))\n",
        "for i in range(20):\n",
        "    j = random.randint(0, len(image))\n",
        "    fig.add_subplot(20, 1, i+1)\n",
        "    plt.xlabel(\"Prediction: \" + prediction[j] +\"   Original: \" + original[j])\n",
        "    plt.imshow(image[j])\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nnwOS5PZS8D",
        "colab": {}
      },
      "source": [
        "def grad_cam(img):\n",
        "\n",
        "  # Convert the image to array of type float32\n",
        "  img = np.asarray(img, dtype = np.float32)\n",
        "\n",
        "  # Reshape the image from (256,256,3) to (1,256,256,3)\n",
        "  img = img.reshape(-1, 256, 256, 3)\n",
        "  img_scaled = img / 255\n",
        "\n",
        "  # Name of the average pooling layer and dense final (you can see these names in the model summary)\n",
        "  classification_layers = [\"Averagea_Pooling\", \"Dense_final\"]\n",
        "\n",
        "  # Last convolutional layer in the model\n",
        "  final_conv = model.get_layer(\"res_5_identity_2_c\")\n",
        "\n",
        "  # Create a model with original model inputs and the last conv_layer as the output\n",
        "  final_conv_model = keras.Model(model.inputs, final_conv.output)\n",
        "\n",
        "  # Then we create the input for classification layer, which is the output of last conv layer\n",
        "  # In our case, output produced by the conv layer is of the shape (1,3,3,2048) \n",
        "  # Since the classification input needs the features as input, we ignore the batch dimension\n",
        "\n",
        "  classification_input = keras.Input(shape = final_conv.output.shape[1:])\n",
        "\n",
        "  # We iterate through the classification layers, to get the final layer and then append \n",
        "  # the layer as the output layer to the classification model.\n",
        "  temp = classification_input\n",
        "  for layer in classification_layers:\n",
        "      temp = model.get_layer(layer)(temp)\n",
        "  classification_model = keras.Model(classification_input, temp)\n",
        "\n",
        "\n",
        "  # We use gradient tape to monitor the 'final_conv_output' to retrive the gradients\n",
        "  # corresponding to the predicted class\n",
        "  with tf.GradientTape() as tape:\n",
        "      # Pass the image through the base model and get the feature map \n",
        "      final_conv_output = final_conv_model(img_scaled)\n",
        "\n",
        "      # Assign gradient tape to monitor the conv_output\n",
        "      tape.watch(final_conv_output)\n",
        "      \n",
        "      # Pass the feature map through the classification model and use argmax to get the \n",
        "      # index of the predicted class and then use the index to get the value produced by final\n",
        "      # layer for that class\n",
        "      prediction = classification_model(final_conv_output)\n",
        "\n",
        "      predicted_class = tf.argmax(prediction[0][0][0])\n",
        "\n",
        "      predicted_class_value = prediction[:,:,:,predicted_class]\n",
        "  \n",
        "  # Get the gradient corresponding to the predicted class based on feature map.\n",
        "  # which is of shape (1,3,3,2048)\n",
        "  gradient = tape.gradient(predicted_class_value, final_conv_output)\n",
        "\n",
        "  # Since we need the filter values (2048), we reduce the other dimensions, \n",
        "  # which would result in a shape of (2048,)\n",
        "  gradient_channels = tf.reduce_mean(gradient, axis=(0, 1, 2))\n",
        "\n",
        "  # We then convert the feature map produced by last conv layer(1,6,6,1536) to (6,6,1536)\n",
        "  final_conv_output = final_conv_output.numpy()[0]\n",
        "\n",
        "  gradient_channels = gradient_channels.numpy()\n",
        "\n",
        "  # We multiply the filters in the feature map produced by final conv layer by the \n",
        "  # filter values that are used to get the predicted class. By doing this we inrease the\n",
        "  # value of areas that helped in making the prediction and lower the vlaue of areas, that \n",
        "  # did not contribute towards the final prediction\n",
        "  for i in range(gradient_channels.shape[-1]):\n",
        "      final_conv_output[:, :, i] *= gradient_channels[i]\n",
        "\n",
        "  # We take the mean accross the channels to get the feature map\n",
        "  heatmap = np.mean(final_conv_output, axis=-1)\n",
        "\n",
        "  # Normalizing the heat map between 0 and 1, to visualize it\n",
        "  heatmap_normalized = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "\n",
        "  # Rescaling and converting the type to int\n",
        "  heatmap = np.uint8(255 * heatmap_normalized )\n",
        "\n",
        "  # Create the colormap\n",
        "  color_map = plt.cm.get_cmap('jet')\n",
        "\n",
        "  # get only the rb features from the heatmap\n",
        "  color_map = color_map(np.arange(256))[:, :3]\n",
        "  heatmap = color_map[heatmap]\n",
        "\n",
        "  # convert the array to image, resize the image and then convert to array\n",
        "  heatmap = keras.preprocessing.image.array_to_img(heatmap)\n",
        "  heatmap = heatmap.resize((256, 256))\n",
        "  heatmap = np.asarray(heatmap, dtype = np.float32)\n",
        "\n",
        "  # Add the heatmap on top of the original image\n",
        "  final_img = heatmap * 0.4 + img[0]\n",
        "  final_img = keras.preprocessing.image.array_to_img(final_img)\n",
        "\n",
        "  return final_img, heatmap_normalized\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F1CFXeOvd0Fe",
        "colab": {}
      },
      "source": [
        "# Visualize the images in the dataset\n",
        "import random\n",
        "fig, axs = plt.subplots(6,3, figsize = (16,32))\n",
        "count = 0\n",
        "for _ in range(6):\n",
        "  i = random.randint(0, len(image))\n",
        "  gradcam, heatmap = grad_cam(image[i])\n",
        "  axs[count][0].title.set_text(\"Original -\" + original[i])\n",
        "  axs[count][0].imshow(image[i])\n",
        "  axs[count][1].title.set_text(\"Heatmap\") \n",
        "  axs[count][1].imshow(heatmap)\n",
        "  axs[count][2].title.set_text(\"Prediction -\" + prediction[i]) \n",
        "  axs[count][2].imshow(gradcam)  \n",
        "  count += 1\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}